{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b339fd1f",
   "metadata": {},
   "source": [
    "# Analyzing Machine Learning Datasets with Generalizability Theory: MNIST Case Study\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Machine learning practitioners often focus on model architecture and optimization techniques, but understanding the variance structure of datasets is equally crucial for developing robust models. This tutorial demonstrates how **Generalizability Theory (G-theory)**, a statistical framework originally developed in psychometrics, can provide valuable insights into machine learning datasets.\n",
    "\n",
    "In this tutorial, we'll apply G-theory to analyze the MNIST handwritten digits dataset from multiple perspectives:\n",
    "\n",
    "1. **Variance Component Analysis**: Understanding how variance is distributed across different facets of the data (pixels, images, digit classes)\n",
    "2. **Data Drift Detection**: Using G-theory to identify and quantify distribution shifts between training and test data\n",
    "3. **Label Reliability**: Assessing how well labels capture the underlying structure of the data\n",
    "4. **Decision Studies (D-studies)**: Exploring how changes to dataset composition affect reliability\n",
    "\n",
    "### What is Generalizability Theory?\n",
    "\n",
    "Generalizability Theory extends classical reliability theory to decompose measurement variance into multiple sources. While classical test theory provides a single reliability coefficient, G-theory provides:\n",
    "\n",
    "- **Variance component estimates** for each facet and their interactions\n",
    "- **Generalizability coefficients (G-coefficients)** that estimate reliability across different measurement designs\n",
    "- **Decision study (D-study) capabilities** to optimize measurement procedures\n",
    "\n",
    "G-theory is particularly valuable in ML contexts because it can:\n",
    "\n",
    "1. Identify which aspects of the data contribute most to variance\n",
    "2. Quantify dataset shift between training and test sets\n",
    "3. Provide guidance on optimal dataset construction\n",
    "4. Help determine whether labels are informative or noisy\n",
    "\n",
    "### Tutorial Roadmap\n",
    "\n",
    "This tutorial will proceed through several steps:\n",
    "\n",
    "1. **Data Preparation**: Reformatting MNIST data for G-theory analysis\n",
    "2. **Basic Analysis**: Understanding the variance structure of the digits\n",
    "3. **Data Drift Experiments**: Simulating and detecting distribution shifts\n",
    "4. **Label Analysis**: Exploring how informative the digit labels are\n",
    "\n",
    "Let's begin by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e696f",
   "metadata": {},
   "source": [
    "## Setup and Required Libraries\n",
    "\n",
    "We'll need several Python libraries for this tutorial:\n",
    "\n",
    "- `torch` and `torchvision`: For loading and processing the MNIST dataset\n",
    "- `generalizit`: The core library for performing generalizability theory analyses\n",
    "- `numpy` and `pandas`: For data manipulation\n",
    "- `matplotlib`: For visualization\n",
    "\n",
    "If you haven't installed these libraries, uncomment and run the pip installation commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3ac16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade pip\n",
    "# !pip install -q generalizit torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b714dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from generalizit import GeneralizIT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49964b",
   "metadata": {},
   "source": [
    "## Loading and Preparing MNIST Data\n",
    "\n",
    "The MNIST dataset is a standard benchmark in machine learning consisting of 28×28 pixel grayscale images of handwritten digits (0-9). It contains 60,000 training images and 10,000 test images.\n",
    "\n",
    "### Key Features of Our Data Loading Approach:\n",
    "\n",
    "1. **Flexible Noise Addition**: We can add controlled noise to either training or test data to simulate data corruption or distribution shift\n",
    "2. **Batch Size of 1**: To simplify processing each image individually\n",
    "3. **No Shuffling**: To maintain consistent order for reproducibility\n",
    "\n",
    "Our `load_mnist_data` function below allows us to manipulate the data in two ways:\n",
    "- Add Gaussian noise to training data (simulating noisy data acquisition)\n",
    "- Multiply test data by a scaling factor (simulating brightness/contrast shifts)\n",
    "\n",
    "These manipulations will be crucial for our experiments on data drift detection later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c341ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Dataset\n",
    "def load_mnist_data(random_training_noise: float = 0, random_test_noise: float = 0,) -> tuple:\n",
    "    \"\"\"\n",
    "    Load MNIST dataset with optional random noise.\n",
    "    \n",
    "    Args:\n",
    "        random_training_noise (float): Standard deviation of random noise for training data.\n",
    "        random_test_noise (float): Standard deviation of random noise for test data.\n",
    "    \n",
    "    Returns:\n",
    "        train_loader: DataLoader for training data.\n",
    "        test_loader: DataLoader for test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define transformations\n",
    "    training_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Ensure input is a tensor\n",
    "        transforms.Lambda(lambda x: x + torch.randn_like(x) * random_training_noise if random_training_noise > 0 else x),\n",
    "        # transforms.Normalize((0.5,), (0.5,))  # Normalize after adding noise\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Ensure input is a tensor\n",
    "        transforms.Lambda(lambda x: x * random_test_noise if random_test_noise > 0 else x),\n",
    "        # transforms.Normalize((0.5,), (0.5,))  # Normalize after adding noise\n",
    "    ])\n",
    "\n",
    "    # Download and load training and test datasets\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=training_transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1f3a1",
   "metadata": {},
   "source": [
    "### Visualizing Sample Images\n",
    "\n",
    "Before proceeding with the analysis, let's visualize some sample images from the MNIST dataset. This helps us understand what we're working with and verify that our data loading procedure is working correctly.\n",
    "\n",
    "The helper function below displays an image along with its label and a sample of pixel values. Each MNIST image is 28×28 pixels in size, with each pixel represented as a grayscale value between 0 (black) and 1 (white)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990d273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_helper(image, label):\n",
    "    # Extract the image data for display (removing batch and channel dimensions)\n",
    "    img_to_display = image[0, 0]  # Shape: [28, 28]\n",
    "    \n",
    "    # Print the label (which is a single value)\n",
    "    print(\"Image label:\", label.item())\n",
    "    \n",
    "    # Print a sample of pixel values instead of all pixels\n",
    "    print(\"Sample of pixel values (first row):\", img_to_display[0])\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(img_to_display.cpu().numpy(), cmap='gray')\n",
    "    plt.title(f\"Label: {label.item()}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24472c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_helper(dataloader, data_rows, dataset, label_counts, images_per_label, processed_count, num_images):\n",
    "    # Properly iterate through the dataloader\n",
    "    train_iterator = iter(dataloader)\n",
    "    while processed_count < num_images:\n",
    "        try:\n",
    "            images, labels = next(train_iterator)\n",
    "        except StopIteration:\n",
    "            # Restart iterator if we reach the end but haven't processed enough images\n",
    "            train_iterator = iter(dataloader)\n",
    "            images, labels = next(train_iterator)\n",
    "        \n",
    "        # Process each image in the batch\n",
    "        for idx in range(len(images)):\n",
    "            image = images[idx]\n",
    "            label = labels[idx]\n",
    "            \n",
    "            # Only process if we need more images for this label\n",
    "            if label_counts[label.item()] < images_per_label:\n",
    "                # Convert the image to a numpy array and flatten it\n",
    "                image_array = image.numpy().flatten()\n",
    "                \n",
    "                # For each pixel in the image, create a row\n",
    "                for pixel_idx, pixel_value in enumerate(image_array):\n",
    "                    data_rows.append({\n",
    "                        'dataset': dataset,\n",
    "                        'image': processed_count,\n",
    "                        'label': int(label),\n",
    "                        'pixel': pixel_idx,\n",
    "                        'value': pixel_value\n",
    "                    })\n",
    "                \n",
    "                label_counts[label.item()] += 1  # Increment the count for this label\n",
    "                processed_count += 1  # Increment the count for processed images\n",
    "                \n",
    "                # # Print progress every 5 images\n",
    "                # if processed_count % 5 == 0:\n",
    "                #     print(f\"Processing train image {processed_count}/{num_images}\")\n",
    "                \n",
    "                # Check if we've processed enough images\n",
    "                if processed_count >= num_images:\n",
    "                    return data_rows, label_counts, processed_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98717c",
   "metadata": {},
   "source": [
    "## Reconfiguring Data for Generalizability Analysis\n",
    "\n",
    "Generalizability Theory requires data to be organized in a specific format that identifies the different facets (sources of variation) in the measurement design. For our MNIST analysis, we need to transform the data from its original 2D image format into a long-format dataset where each row represents a single pixel value with all relevant facets identified.\n",
    "\n",
    "### Our Nested Design Structure:\n",
    "\n",
    "We'll organize our data in a nested design structure represented as `pixel:image:label`, where:\n",
    "- `label` (0-9): The digit category (highest level of nesting)\n",
    "- `image` (0-N): Individual images within each digit category\n",
    "- `pixel` (0-783): Each pixel within an image (28×28=784 pixels)\n",
    "\n",
    "This design allows us to answer questions like:\n",
    "1. How much variance is explained by digit categories (labels)?\n",
    "2. How much variance exists between different images of the same digit?\n",
    "3. How do pixel values vary within images of the same digit?\n",
    "\n",
    "### The Data Preparation Function:\n",
    "\n",
    "The `prepare_data` function below:\n",
    "1. Loads the MNIST dataset with optional noise\n",
    "2. Displays a sample image if requested\n",
    "3. Processes a subset of images\n",
    "4. Transforms the data into the long format required for G-theory analysis\n",
    "5. Optionally processes both training and test data for comparative analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8f83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_data(\n",
    "    num_images=20,\n",
    "    num_images_test=20, \n",
    "    random_training_noise: float = 0.0, \n",
    "    random_test_noise: float = 0.0, \n",
    "    display: bool = True, \n",
    "    test:bool = False) -> pd.DataFrame:  \n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame to store the pixel values and labels in a long format.\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset\n",
    "    train_dataloader, test_dataloader = load_mnist_data(random_training_noise=random_training_noise, random_test_noise=random_test_noise)\n",
    "    \n",
    "    all_data_rows = []\n",
    "    \n",
    "    # Display the first image and label if requested\n",
    "    if display:\n",
    "        first_batch = next(iter(train_dataloader))\n",
    "        first_image, first_label = first_batch\n",
    "        print(\"Displaying first image and label:\")\n",
    "        display_image_helper(first_image, first_label)\n",
    "    \n",
    "    # Create a dictionary to keep track of how many images of each label we've processed\n",
    "    train_label_counts = {i: 0 for i in range(10)}\n",
    "    images_per_label = num_images // 10  # Ensure even distribution of digits 0-9\n",
    "    \n",
    "    # Process training dataset\n",
    "    train_processed_count = 0\n",
    "    _, train_label_counts, train_processed_count = create_df_helper(\n",
    "        train_dataloader,\n",
    "        all_data_rows, \n",
    "        'train',\n",
    "        train_label_counts, \n",
    "        images_per_label, \n",
    "        train_processed_count, \n",
    "        num_images\n",
    "    )\n",
    "\n",
    "    print(f\"Processed {train_processed_count} train images\")\n",
    "    \n",
    "    if test:\n",
    "        # Process test dataset with a fresh counter for each label\n",
    "        test_label_counts = {i: 0 for i in range(10)}\n",
    "        test_images_per_label = num_images_test // 10\n",
    "        test_processed_count = 0\n",
    "        _, test_label_counts, test_processed_count = create_df_helper(\n",
    "            test_dataloader, \n",
    "            all_data_rows,\n",
    "            'test',\n",
    "            test_label_counts, \n",
    "            test_images_per_label, \n",
    "            test_processed_count, \n",
    "            num_images_test\n",
    "        )\n",
    "        # Remove this line: all_data_rows.extend(test_data_rows)\n",
    "        print(f\"Processed {test_processed_count} test images\")\n",
    "\n",
    "    # Create the DataFrame from all collected data\n",
    "    nested_data_df = pd.DataFrame(all_data_rows)\n",
    "\n",
    "    return nested_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb48feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying first image and label:\n",
      "Image label: 5\n",
      "Sample of pixel values (first row): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 train images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>pixel</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15675</th>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>779</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15676</th>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15677</th>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15678</th>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>782</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15679</th>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15680 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset  image  label  pixel  value\n",
       "0       train      0      5      0    0.0\n",
       "1       train      0      5      1    0.0\n",
       "2       train      0      5      2    0.0\n",
       "3       train      0      5      3    0.0\n",
       "4       train      0      5      4    0.0\n",
       "...       ...    ...    ...    ...    ...\n",
       "15675   train     19      8    779    0.0\n",
       "15676   train     19      8    780    0.0\n",
       "15677   train     19      8    781    0.0\n",
       "15678   train     19      8    782    0.0\n",
       "15679   train     19      8    783    0.0\n",
       "\n",
       "[15680 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_data_df = prepare_data()\n",
    "nested_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b5e11",
   "metadata": {},
   "source": [
    "## Defining the Generalizability Study (G-Study) Design\n",
    "\n",
    "Now that we have prepared our data, we need to define the structure of our G-Study. In Generalizability Theory, this involves specifying the measurement design that represents the hierarchical or crossed relationships between facets.\n",
    "\n",
    "### Our Nested Design: `pixel:image:label`\n",
    "\n",
    "For our MNIST analysis, we'll use a fully nested design where:\n",
    "- Pixels (p) are nested within images (i)\n",
    "- Images (i) are nested within digit labels (l)\n",
    "\n",
    "This is represented in G-theory notation as `pixel:image:label` or `p:i:l`.\n",
    "\n",
    "#### What Does This Design Tell Us?\n",
    "\n",
    "With this design, we're asking:\n",
    "1. **How much variation is due to different digit categories?** (The 'label' facet)\n",
    "2. **How much variation exists between different images of the same digit?** (The 'image:label' facet)\n",
    "3. **How much variation exists among pixels within the same image?** (The 'pixel:image:label' facet)\n",
    "\n",
    "These variance components will help us understand if the dataset's structure aligns with how we expect machine learning models to learn from it. For example:\n",
    "- **High label variance**: Suggests clear distinctions between digit classes (desirable)\n",
    "- **High image:label variance**: Suggests high variability within each digit class (could make learning challenging)\n",
    "- **High pixel:image:label variance**: Suggests high pixel-level noise or detail\n",
    "\n",
    "Let's initialize our GeneralizIT object with this design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eefeb227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The following columns have been dropped from the data:\n",
      "dataset\n"
     ]
    }
   ],
   "source": [
    "# Define Generalizability Study Design\n",
    "design_str = \"pixel:image:label\"\n",
    "\n",
    "# Initialize GeneralizIT\n",
    "gt = GeneralizIT(\n",
    "    data=nested_data_df,\n",
    "    design_str=design_str,\n",
    "    response=\"value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3963e0f",
   "metadata": {},
   "source": [
    "## Variance Component Analysis\n",
    "\n",
    "Now we'll perform an Analysis of Variance (ANOVA) to decompose the total variance in our data into components associated with each facet in our design. This is a key step in G-theory analysis.\n",
    "\n",
    "### What Are Variance Components?\n",
    "\n",
    "Variance components represent the amount of variance attributed to different sources in our measurement design:\n",
    "\n",
    "1. **Label variance (σ²ₗ)**: Variance due to differences between digit categories\n",
    "2. **Image:Label variance (σ²ᵢ:ₗ)**: Variance due to differences between images within each digit category\n",
    "3. **Pixel:Image:Label variance (σ²ₚ:ᵢ:ₗ)**: Residual variance at the pixel level\n",
    "\n",
    "The GeneralizIT package uses a method called \"Analogous ANOVA\" based on Henderson's Method 1, which can handle unbalanced designs and missing data.\n",
    "\n",
    "Let's calculate and examine these variance components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca8df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Component Analysis for Unnormalized Data:\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                  label           image:label     pixel:image:label mean            T               Variance       \n",
      "label             15680.0000      7840.0000       10.0000           15680.0000      243.9211        0.0004         \n",
      "image:label       15680.0000      15680.0000      20.0000           15680.0000      250.3084        0.0007         \n",
      "pixel:image:label 15680.0000      15680.0000      15680.0000        15680.0000      1613.9019       0.0871         \n",
      "mean              1568.0000       784.0000        1.0000            15680.0000      232.3996        0.0147         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Variance Component Analysis\n",
    "print(\"Variance Component Analysis for Unnormalized Data:\")\n",
    "gt.calculate_anova()\n",
    "gt.anova_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e225b",
   "metadata": {},
   "source": [
    "### Interpreting the Variance Components\n",
    "\n",
    "Let's interpret the variance components from the ANOVA table above:\n",
    "\n",
    "1. **Label variance**: The variance attributed to differences between digit classes (0-9). A high value suggests that different digits have distinctly different pixel patterns, which is essential for classification tasks.\n",
    "\n",
    "2. **Image:Label variance**: The variance attributed to differences between images within the same digit class. This captures how varied the handwriting styles are within each digit category.\n",
    "\n",
    "3. **Pixel:Image:Label variance**: The residual variance at the pixel level, which includes both meaningful variation (like stroke width) and noise.\n",
    "\n",
    "The relative magnitude of these components tells us where most of the variation in our dataset comes from. For an ideal classification dataset:\n",
    "\n",
    "- Label variance should be high (clear distinction between classes)\n",
    "- Image:Label variance should be moderate (variations within class should exist but not overwhelm class distinctions)\n",
    "- Pixel:Image:Label variance should be low (minimal noise at the pixel level)\n",
    "\n",
    "Next, we'll calculate generalizability coefficients to quantify how reliably our design can distinguish between different facets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46288be1",
   "metadata": {},
   "source": [
    "## Generalizability Analysis\n",
    "\n",
    "Generalizability analysis provides coefficients that quantify how reliably we can generalize from our observed data to the universe of admissible observations. In machine learning terms, this translates to how well patterns in our training data represent the true underlying patterns.\n",
    "\n",
    "### G-Coefficients: Quantifying Reliability\n",
    "\n",
    "G-theory provides two key coefficients:\n",
    "\n",
    "1. **Generalizability coefficient (ρ²)**: For relative decisions (comparing entities). In ML terms, this relates to how well we can rank or classify examples.\n",
    "   - Values closer to 1 indicate higher reliability for making relative comparisons.\n",
    "\n",
    "2. **Dependability coefficient (Φ)**: For absolute decisions (precise measurements). In ML terms, this relates to how well we can predict exact values.\n",
    "   - Values closer to 1 indicate higher reliability for making absolute judgments.\n",
    "   - This coefficient is typically lower than ρ² as it accounts for all sources of error.\n",
    "\n",
    "Let's calculate these coefficients for our MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31c2b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalizability Analysis:\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "label           0.4966          0.4966         \n",
      "image:label     0.9083          0.9083         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Generalizability Analysis:\")\n",
    "gt.calculate_g_coefficients()\n",
    "gt.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32d11a",
   "metadata": {},
   "source": [
    "### Interpreting the G-Coefficients\n",
    "\n",
    "The generalizability coefficients above tell us how reliably our measurement design can distinguish between the different facets in our design. Let's interpret what these mean for our MNIST data:\n",
    "\n",
    "- **For the label facet**: This indicates how reliably we can distinguish between different digit categories based on pixel values. A high coefficient suggests clear, consistent differences between digit classes.\n",
    "\n",
    "- **For the image:label facet**: This tells us how reliably we can distinguish between different images of the same digit. A high coefficient here suggests consistent variation patterns within each digit class.\n",
    "\n",
    "High generalizability coefficients for the label facet are particularly important for classification tasks, as they indicate that the class distinctions are reliable and consistent across the dataset. Here, we see that the label facet has a low generalizability coefficient, but the image:label facet has a high coefficient. This suggests high reliability of images within a given label class, but we probably don't have enough data to make reliable distinctions between digit classes on the whole!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8d53b",
   "metadata": {},
   "source": [
    "## Decision Studies (D-studies): Optimizing Dataset Size\n",
    "\n",
    "One of the most powerful features of Generalizability Theory is the ability to conduct Decision Studies (D-studies). D-studies allow us to predict how reliability would change if we modified the measurement design—for instance, by changing the number of images per digit class.\n",
    "\n",
    "### What Are D-studies?\n",
    "\n",
    "D-studies use the variance components estimated in a G-study to simulate alternative designs with different sample sizes or facet structures. This can help answer questions like:\n",
    "\n",
    "1. **How many images per class do we need for reliable classification?**\n",
    "2. **Would increasing dataset size beyond a certain point yield diminishing returns?**\n",
    "3. **What is the optimal balance between dataset size and computational cost?**\n",
    "\n",
    "Let's conduct a D-study to predict the reliability we would achieve if we increased our dataset from 20 to 50 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397d3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a d study increasing the number of images from 25 to 50\n",
    "d_study_design = {\n",
    "    'label': [10],\n",
    "    'image': [50],\n",
    "    'pixel': [784]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e7a29e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Balanced D-Study Design for the provided designs\n",
      "Top level facets: ['label']\n",
      "Ordered facets after processing: ['label', 'image', 'pixel']\n",
      "Ordered facets for nested structure: ['pixel', 'image', 'label']\n",
      "   image  label  pixel\n",
      "0      1      1      1\n",
      "1      1      2      1\n",
      "2      1      3      1\n",
      "3      1      4      1\n",
      "4      1      5      1\n",
      "Using user-provided variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "Using User Provided Levels Coefficients\n"
     ]
    }
   ],
   "source": [
    "gt.calculate_d_study(d_study_design=d_study_design, error_variance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455227a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "D-Study: label: 10, image: 50, pixel: 784\n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "label           0.9610          0.9610         \n",
      "image:label     0.9083          0.9083         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt.d_study_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40f2e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "dataset\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                  label           image:label     pixel:image:label mean            T               Variance       \n",
      "label             39200.0000      7840.0000       10.0000           39200.0000      671.7207        0.0012         \n",
      "image:label       39200.0000      39200.0000      50.0000           39200.0000      701.8969        0.0008         \n",
      "pixel:image:label 39200.0000      39200.0000      39200.0000        39200.0000      4202.2487       0.0894         \n",
      "mean              3920.0000       784.0000        1.0000            39200.0000      621.5715        0.0157         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "label           0.8678          0.8678         \n",
      "image:label     0.9461          0.9461         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nested_data_50_df = prepare_data(num_images=50, display=False)\n",
    "gt_50 = GeneralizIT(\n",
    "    data=nested_data_50_df,\n",
    "    design_str=design_str,\n",
    "    response=\"value\"\n",
    ")\n",
    "\n",
    "gt_50.calculate_anova()\n",
    "gt_50.anova_summary()\n",
    "gt_50.calculate_g_coefficients()\n",
    "gt_50.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9718178",
   "metadata": {},
   "source": [
    "### Validating D-study Predictions\n",
    "\n",
    "After conducting a D-study to predict how reliability would change with increased dataset size, it's valuable to validate these predictions with actual data. Let's compare our D-study prediction against a real dataset with 50 images:\n",
    "\n",
    "1. **D-study prediction**: We saw that increasing the number of images per class significantly improved reliability\n",
    "2. **Actual 50-image dataset**: Performing the same G-study on 50 sampled images confirms that label reliability increases as predicted, though not as significantly\n",
    "    - Greater variance at the pixel:image:label level than suggested by the original dataset\n",
    "3. **Limitations**: The G-Study predictions were a one off, bootstrapping the sample of images could have given us a 95% confidence interval for the variance values (and hence D-Study coefficients) for which the new dataset would probabaly fall into\n",
    "\n",
    "This comparison demonstrates that our hunch was correct! The MNIST digits already delineate the classes well, so increasing the number of images per class improves the overall reliability of our labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd0213",
   "metadata": {},
   "source": [
    "## Investigating Noise Resilience\n",
    "\n",
    "In real-world machine learning scenarios, datasets often contain various types of noise. Understanding how noise affects data structure is crucial for developing robust models. Let's explore how different levels of noise impact the variance components and G-coefficients in our MNIST data.\n",
    "\n",
    "### Noise Experiment Design\n",
    "\n",
    "We'll add increasing levels of Gaussian noise to our training images and analyze how this affects:\n",
    "\n",
    "1. **Variance distribution**: How does noise shift the balance between label, image, and pixel variance?\n",
    "2. **G-coefficients**: How does noise affect the reliability of digit classification?\n",
    "3. **Visual recognition**: At what noise level do digits become unrecognizable?\n",
    "\n",
    "This experiment simulates real-world scenarios where sensor noise, transmission errors, or preprocessing artifacts might corrupt image data. The results will help us understand the robustness of digit classification under noisy conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04838979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise level: 0.1\n",
      "Displaying first image and label:\n",
      "Image label: 5\n",
      "Sample of pixel values (first row): tensor([-0.1045, -0.0283,  0.0532,  0.0080, -0.1043, -0.0240,  0.1562, -0.0475,\n",
      "         0.0455, -0.0408, -0.2257,  0.0657, -0.2331,  0.0005,  0.0672, -0.0367,\n",
      "         0.0166, -0.0763, -0.0545, -0.0234,  0.1522, -0.0036, -0.1243, -0.0124,\n",
      "         0.0370, -0.1152, -0.1194,  0.2302])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "dataset\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                  label           image:label     pixel:image:label mean            T               Variance       \n",
      "label             39200.0000      7840.0000       10.0000           39200.0000      670.8823        0.0013         \n",
      "image:label       39200.0000      39200.0000      50.0000           39200.0000      700.6139        0.0008         \n",
      "pixel:image:label 39200.0000      39200.0000      39200.0000        39200.0000      4594.8208       0.0995         \n",
      "mean              3920.0000       784.0000        1.0000            39200.0000      618.8927        0.0156         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "label           0.8752          0.8752         \n",
      "image:label     0.9430          0.9430         \n",
      "\n",
      "\n",
      "noise level: 0.5\n",
      "Displaying first image and label:\n",
      "Image label: 5\n",
      "Sample of pixel values (first row): tensor([-0.3899, -0.3136,  0.0259, -0.0679, -0.3824, -0.8542,  0.0449, -0.6224,\n",
      "        -0.3906, -0.2532, -0.3014, -0.0226, -0.0430, -0.6742,  0.4698, -0.0678,\n",
      "         0.6176, -0.1318,  0.4127, -0.4063, -0.3470,  0.0100, -0.4466,  0.6693,\n",
      "        -0.1893, -0.6280,  0.2170, -1.0433])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "dataset\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                  label           image:label     pixel:image:label mean            T               Variance       \n",
      "label             39200.0000      7840.0000       10.0000           39200.0000      691.7026        0.0013         \n",
      "image:label       39200.0000      39200.0000      50.0000           39200.0000      728.2869        0.0007         \n",
      "pixel:image:label 39200.0000      39200.0000      39200.0000        39200.0000      13997.6214      0.3389         \n",
      "mean              3920.0000       784.0000        1.0000            39200.0000      637.4674        0.0161         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "label           0.8516          0.8516         \n",
      "image:label     0.8223          0.8223         \n",
      "\n",
      "\n",
      "noise level: 0.9\n",
      "Displaying first image and label:\n",
      "Image label: 5\n",
      "Sample of pixel values (first row): tensor([ 0.5783,  0.7388, -1.1301,  1.1706, -1.0722, -1.3865,  0.3865,  1.3514,\n",
      "        -0.1738, -1.1938, -0.7744, -0.1641, -1.4470, -0.1462, -0.5959, -0.9557,\n",
      "         1.8142, -1.9045,  0.3105,  0.9184, -0.9938,  0.9282, -2.2091,  0.8256,\n",
      "        -1.2297,  1.0494,  0.6295, -0.2189])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "dataset\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                  label           image:label     pixel:image:label mean            T               Variance       \n",
      "label             39200.0000      7840.0000       10.0000           39200.0000      702.9242        0.0018         \n",
      "image:label       39200.0000      39200.0000      50.0000           39200.0000      771.3850        0.0010         \n",
      "pixel:image:label 39200.0000      39200.0000      39200.0000        39200.0000      35992.3108      0.8996         \n",
      "mean              3920.0000       784.0000        1.0000            39200.0000      623.9658        0.0157         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "label           0.8074          0.8074         \n",
      "image:label     0.7093          0.7093         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for noise_level in [0.1, 0.5, 0.9]:\n",
    "    print(f\"noise level: {noise_level}\")\n",
    "    train_noise_df = prepare_data(random_training_noise=noise_level, num_images=50, display=True)\n",
    "    gt_train_noise = GeneralizIT(\n",
    "        data=train_noise_df,\n",
    "        design_str=design_str,\n",
    "        response=\"value\"\n",
    "    )\n",
    "    gt_train_noise.calculate_anova()\n",
    "    gt_train_noise.anova_summary()\n",
    "    gt_train_noise.calculate_g_coefficients()\n",
    "    gt_train_noise.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f5587",
   "metadata": {},
   "source": [
    "### Interpreting Noise Experiment Results\n",
    "\n",
    "As we add increasing levels of noise to our MNIST images, we observe several key patterns:\n",
    "\n",
    "1. **Visual Impact**: At low noise levels (0.1), digits remain recognizable. At medium levels (0.5), recognition becomes challenging. At high levels (0.9), many digits become indistinguishable to humans.\n",
    "\n",
    "2. **Variance Shifts**: Notice how the distribution of variance changes across noise levels:\n",
    "   - As noise increases, the pixel:image:label variance (residual/noise variance) grows relative to the label variance\n",
    "   - This represents the signal-to-noise ratio degrading as noise overwhelms the true signal\n",
    "\n",
    "3. **G-Coefficient Degradation**: The generalizability coefficients for the label facet typically decrease as noise increases, indicating reduced reliability for digit classification\n",
    "\n",
    "These findings have important implications for ML model training:\n",
    "- Models trained on low-noise data may fail when deployed on noisier real-world data (explored in later sections)\n",
    "- Data augmentation with controlled noise can improve model robustness\n",
    "- G-theory provides a quantitative framework for determining acceptable noise thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ce86d",
   "metadata": {},
   "source": [
    "# Detecting and Analyzing Data Drift\n",
    "\n",
    "Data drift—the phenomenon where the statistical properties of model inputs change over time—is a major challenge in maintaining machine learning models in production. Generalizability Theory offers a powerful framework for detecting and quantifying data drift by analyzing variance components across different datasets.\n",
    "\n",
    "## Data Drift Experiments\n",
    "\n",
    "In this section, we'll simulate and analyze different types of data drift scenarios:\n",
    "\n",
    "1. **Distribution Shift**: Using brightness scaling to create a consistent shift between training and test data\n",
    "2. **Image Noise**: Adding noise specifically to the training set to simulate corrupted labels\n",
    "\n",
    "These experiments will demonstrate how G-theory can detect data drift and help explain data augmentation, helping ML practitioners gain deeper insights into the reliability of model performance on a given dataset and potential to improve model training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98919cc",
   "metadata": {},
   "source": [
    "### Experiment 1: Training vs. Test Set Comparison\n",
    "\n",
    "Let's start with a basic comparison between training and test sets. Without any artificial drift, we expect training and test sets from the same distribution (like MNIST) to have similar variance structures.\n",
    "\n",
    "We'll use a design structure where:\n",
    "- Dataset (train/test) is the highest level facet\n",
    "- Images are nested within datasets\n",
    "- Pixels are nested within images\n",
    "\n",
    "**Research Question**: Is there a natural drift between the MNIST training and test sets as distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679d629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "label\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                    dataset         image:dataset   pixel:image:dataset mean            T               Variance       \n",
      "dataset             78400.0000      1568.0000       2.0000              78400.0000      1208.1680       -0.0000        \n",
      "image:dataset       78400.0000      78400.0000      100.0000            78400.0000      1354.1257       0.0018         \n",
      "pixel:image:dataset 78400.0000      78400.0000      78400.0000          78400.0000      8246.4122       0.0880         \n",
      "mean                39200.0000      784.0000        1.0000              78400.0000      1207.9148       0.0154         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_data_df = prepare_data(num_images=50, num_images_test=50, test=True, display=False)\n",
    "\n",
    "train_test_design_str = \"pixel:image:dataset\"\n",
    "\n",
    "gt_train_test = GeneralizIT(\n",
    "    data=train_test_data_df,\n",
    "    design_str=train_test_design_str,\n",
    "    response=\"value\"\n",
    ")\n",
    "\n",
    "gt_train_test.calculate_anova()\n",
    "gt_train_test.anova_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66a86e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "dataset         0.0000          0.0000         \n",
      "image:dataset   0.9413          0.9413         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt_train_test.calculate_g_coefficients()\n",
    "gt_train_test.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29045621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>pixel</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78395</th>\n",
       "      <td>test</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>779</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78396</th>\n",
       "      <td>test</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78397</th>\n",
       "      <td>test</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78398</th>\n",
       "      <td>test</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>782</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78399</th>\n",
       "      <td>test</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset  image  label  pixel  value\n",
       "0       train      0      5      0    0.0\n",
       "1       train      0      5      1    0.0\n",
       "2       train      0      5      2    0.0\n",
       "3       train      0      5      3    0.0\n",
       "4       train      0      5      4    0.0\n",
       "...       ...    ...    ...    ...    ...\n",
       "78395    test     49      8    779    0.0\n",
       "78396    test     49      8    780    0.0\n",
       "78397    test     49      8    781    0.0\n",
       "78398    test     49      8    782    0.0\n",
       "78399    test     49      8    783    0.0\n",
       "\n",
       "[78400 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06746fd6",
   "metadata": {},
   "source": [
    "### Results: No Natural Drift in MNIST\n",
    "\n",
    "The G-coefficients for the dataset facet are effectively 0, confirming there is no significant variance attributable to differences between training and test sets. This matches our expectation for MNIST, which was carefully curated to ensure training and test sets have similar distributions.\n",
    "\n",
    "**Key Insight**: Low G-coefficients for the dataset facet indicate that models trained on the training set should generalize well to the test set without drift-related issues.\n",
    "\n",
    "### Experiment 2: Simulating Distribution Shift\n",
    "\n",
    "Now, let's introduce an artificial distribution shift by scaling the brightness of test images. We'll use scaling factors of 0.75, 0.85, and 0.95 (where lower values create darker images).\n",
    "\n",
    "**Research Question**: At what point does brightness shift create detectable data drift, and how sensitive is G-theory to detecting it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324896f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- noise level: 0.75 --------------------\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "label\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                    dataset         image:dataset   pixel:image:dataset mean            T               Variance       \n",
      "dataset             78400.0000      1568.0000       2.0000              78400.0000      951.5321        0.0006         \n",
      "image:dataset       78400.0000      78400.0000      100.0000            78400.0000      1068.7756       0.0014         \n",
      "pixel:image:dataset 78400.0000      78400.0000      78400.0000          78400.0000      6477.0906       0.0691         \n",
      "mean                39200.0000      784.0000        1.0000              78400.0000      928.6393        0.0116         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "dataset         0.9527          0.9527         \n",
      "image:dataset   0.9578          0.9578         \n",
      "\n",
      "\n",
      "-------------------- noise level: 0.85 --------------------\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "label\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                    dataset         image:dataset   pixel:image:dataset mean            T               Variance       \n",
      "dataset             78400.0000      1568.0000       2.0000              78400.0000      1045.3875       0.0002         \n",
      "image:dataset       78400.0000      78400.0000      100.0000            78400.0000      1173.1323       0.0016         \n",
      "pixel:image:dataset 78400.0000      78400.0000      78400.0000          78400.0000      7124.1570       0.0760         \n",
      "mean                39200.0000      784.0000        1.0000              78400.0000      1035.9499       0.0131         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "dataset         0.8549          0.8549         \n",
      "image:dataset   0.9489          0.9489         \n",
      "\n",
      "\n",
      "-------------------- noise level: 0.95 --------------------\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "Warning: The following columns have been dropped from the data:\n",
      "label\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                    dataset         image:dataset   pixel:image:dataset mean            T               Variance       \n",
      "dataset             78400.0000      1568.0000       2.0000              78400.0000      1150.9749       0.0000         \n",
      "image:dataset       78400.0000      78400.0000      100.0000            78400.0000      1290.5334       0.0017         \n",
      "pixel:image:dataset 78400.0000      78400.0000      78400.0000          78400.0000      7852.1061       0.0838         \n",
      "mean                39200.0000      784.0000        1.0000              78400.0000      1149.1268       0.0146         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                Φ               ρ²             \n",
      "dataset         0.0000          0.0000         \n",
      "image:dataset   0.9408          0.9408         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dim the test data\n",
    "for random_test_noise in [0.75, 0.85, 0.95]:\n",
    "    print(f\"{'-'*20} noise level: {random_test_noise} {'-'*20}\")\n",
    "    train_test_data_df = prepare_data(num_images=50, num_images_test=50, random_test_noise=random_test_noise, test=True, display=False)\n",
    "\n",
    "    train_test_design_str = \"pixel:image:dataset\"\n",
    "\n",
    "    gt_train_test = GeneralizIT(\n",
    "        data=train_test_data_df,\n",
    "        design_str=train_test_design_str,\n",
    "        response=\"value\"\n",
    "    )\n",
    "\n",
    "    gt_train_test.calculate_anova()\n",
    "    gt_train_test.anova_summary()\n",
    "    gt_train_test.calculate_g_coefficients()\n",
    "    gt_train_test.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6f113",
   "metadata": {},
   "source": [
    "### Results: Brightness Shift Detection\n",
    "\n",
    "As we increase the brightness shift (decreasing the scaling factor from 0.95 to 0.75), we observe:\n",
    "\n",
    "1. **Increasing Dataset Variance**: The variance attributed to dataset differences grows substantially\n",
    "2. **Rising G-coefficients**: The G-coefficients for the dataset facet increase, indicating that the dataset distinction becomes more reliable\n",
    "3. **Threshold Effect**: There appears to be a threshold at which drift becomes clearly detectable in the variance components\n",
    "    - For example, between 0.95 and 0.85, the $\\rho^2$ coefficient jumps from 0 to > 0.8, indicating a significant change in reliability\n",
    "\n",
    "**Key Insight**: G-theory provides a quantitative measure of drift severity through G-coefficients, which can be used to establish thresholds for automated drift detection systems.\n",
    "\n",
    "### Experiment 3: Complex Drift with Label Interactions\n",
    "\n",
    "Real-world drift often involves complex interactions between features and labels. Imagine that we not only have access to the raw data (images in the case of MNIST) but we've also labeled the new incoming `test` data. In our universe of generalizability we assume that images derive structure from each label, but are influenced by the data generating process they are sampled from. Thus for each dataset, we have a `pixel:image:label` triplet. Where `dataset` is either `train` or `test` corresponding to the brightness scaling factor as the data generating process.\n",
    "\n",
    "**Design**: `(pixel:image:label) x dataset`\n",
    "\n",
    "This design allows us to assess:\n",
    "1. Main effect of dataset drift\n",
    "2. Main effect of label reliability\n",
    "3. Interaction between labels and datasets (dataset x label)\n",
    "4. Nested reliability of images within labels (image:label)\n",
    "    - This captures how well images represent their labels\n",
    "5. Residual noise at the pixel level (pixel:image:label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed194c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Processed 50 test images\n"
     ]
    }
   ],
   "source": [
    "train_test_data_df = prepare_data(num_images=50, num_images_test=50, random_test_noise=.75, test=True, display=False)\n",
    "\n",
    "train_test_design_str = \"(pixel:image:label) x dataset\"\n",
    "variance_tuple_dictionary = {\n",
    "    \"dataset\": (\"dataset\",),\n",
    "    \"label\": (\"label\",),\n",
    "    \"dataset x label\": (\"dataset\", \"label\"),\n",
    "    \"image:label\": (\"image\", \"label\"),\n",
    "    \"(image:label) x dataset\": (\"image\", \"label\", \"dataset\"),\n",
    "    \"pixel:image:label\": (\"pixel\", \"image\", \"label\"),\n",
    "    \"(pixel:image:label) x dataset\": (\"pixel\", \"image\", \"label\", \"dataset\"),\n",
    "    \"mean\": ()\n",
    "}\n",
    "\n",
    "gt_train_test = GeneralizIT(\n",
    "    data=train_test_data_df,\n",
    "    design_str=train_test_design_str,\n",
    "    response=\"value\",\n",
    "    variance_tuple_dictionary=variance_tuple_dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3ca522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                              dataset         label           dataset x label image:label     (image:label) x dataset pixel:image:label (pixel:image:label) x dataset mean            T               Variance       \n",
      "dataset                       78400.0000      7840.0000       7840.0000       1568.0000       1568.0000               2.0000            2.0000                        78400.0000      951.5321        0.0006         \n",
      "label                         39200.0000      78400.0000      39200.0000      8310.4000       7840.0000               10.6000           10.0000                       78400.0000      991.0083        0.0007         \n",
      "dataset x label               78400.0000      78400.0000      78400.0000      15680.0000      15680.0000              20.0000           20.0000                       78400.0000      1024.3599       0.0002         \n",
      "image:label                   76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              100.0000          97.0000                       78400.0000      1067.4042       0.0008         \n",
      "(image:label) x dataset       78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              100.0000          100.0000                      78400.0000      1068.7756       -0.0002        \n",
      "pixel:image:label             76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              78400.0000        76048.0000                    78400.0000      6401.3129       0.0374         \n",
      "(pixel:image:label) x dataset 78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              78400.0000        78400.0000                    78400.0000      6477.0906       0.0317         \n",
      "mean                          39200.0000      7840.0000       3920.0000       831.0400        784.0000                1.0600            1.0000                        78400.0000      928.6393        0.0115         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "Warning: Negative variance components found for Index(['(image:label) x dataset'], dtype='object'). Setting to 0.\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                        Φ               ρ²             \n",
      "dataset                 0.8477          0.9665         \n",
      "label                   0.5863          0.7831         \n",
      "dataset x label         0.8941          0.8941         \n",
      "image:label             0.6315          0.8406         \n",
      "(image:label) x dataset 0.5444          0.9365         \n",
      "pixel:image:label       0.5374          0.5497         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt_train_test.calculate_anova()\n",
    "gt_train_test.anova_summary()\n",
    "gt_train_test.calculate_g_coefficients()\n",
    "gt_train_test.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4b8e3",
   "metadata": {},
   "source": [
    "### Results: Label-Dataset Interactions\n",
    "\n",
    "The analysis reveals several important insights:\n",
    "\n",
    "1. **Significant Dataset Effect**: The high G-coefficient for the dataset facet (ρ² > 0.8) confirms that the brightness scaling creates detectable drift between training and test sets\n",
    "\n",
    "2. **Label-Dataset Interaction**: The interaction term measures the extent to which labels in the different datasets are able to reliably distinguish between images. The significant G-coefficient for this interaction (ρ² > 0.8) suggests that digits within each respective dataset are able to distinguish between images, but on the whole labels are not a reliable indicator \n",
    "\n",
    "3. **Implications for Model Training**: These results suggest that when incorporating new data into the training set, we should consider:\n",
    "   - Adding more images from both distributions to improve the `label` reliability (data augmentation)\n",
    "   - Another option would be to simply normalize the brightness of the image data as now training and test data would be sampled from the same distribution (for this toy example)\n",
    "\n",
    "G-theory uniquely reveals these nuanced interactions that might not be apparent from aggregate distribution statistics often used for drift detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90418a70",
   "metadata": {},
   "source": [
    "## Data Augmentation with Gaussian Noise\n",
    "In the previous experiments, we focused on brightness scaling as a form of data drift. However, in real-world applications, data can also be corrupted by noise. This can occur due to sensor errors, transmission issues, or other factors that introduce variability into the data. It can be helpful to train models on data that is more robust to noise, which can be achieved through data augmentation techniques.\n",
    "\n",
    "In this section, we'll explore how adding Gaussian noise to the training data affects the variance structure and G-coefficients. \n",
    "\n",
    "### Experiment #4: Gaussian Noise Addition\n",
    "\n",
    "**Design**: `(pixel:image:label) x dataset`\n",
    "\n",
    "We'll add Gaussian noise to the training images and leave the test images as they are provided (i.e. no contrast shift). Given that train and test images from MNIST and just split from the same dataset, there should be no difference in the underlying distributions and variance from `dataset` will be ~ 0. We will analyze how gaussian noise affects:\n",
    "1. **Variance distribution**: How does noise shift the balance between label, image, and pixel variance?\n",
    "2. **G-coefficients**: How does noise affect the reliability of digit classification?\n",
    "3. **Visual recognition**: At what noise level do digits become unrecognizable?\n",
    "\n",
    "**Research Question**: How does adding Gaussian noise to the training data affect the variance structure and G-coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eec9c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "-------------------- noise level: 0 --------------------\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                              dataset         label           dataset x label image:label     (image:label) x dataset pixel:image:label (pixel:image:label) x dataset mean            T               Variance       \n",
      "dataset                       78400.0000      7840.0000       7840.0000       1568.0000       1568.0000               2.0000            2.0000                        78400.0000      1208.1680       -0.0000        \n",
      "label                         39200.0000      78400.0000      39200.0000      8310.4000       7840.0000               10.6000           10.0000                       78400.0000      1287.7552       0.0010         \n",
      "dataset x label               78400.0000      78400.0000      78400.0000      15680.0000      15680.0000              20.0000           20.0000                       78400.0000      1298.6349       0.0001         \n",
      "image:label                   76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              100.0000          97.0000                       78400.0000      1353.7835       0.0008         \n",
      "(image:label) x dataset       78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              100.0000          100.0000                      78400.0000      1354.1257       -0.0000        \n",
      "pixel:image:label             76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              78400.0000        76048.0000                    78400.0000      8154.3861       0.0490         \n",
      "(pixel:image:label) x dataset 78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              78400.0000        78400.0000                    78400.0000      8246.4122       0.0390         \n",
      "mean                          39200.0000      7840.0000       3920.0000       831.0400        784.0000                1.0600            1.0000                        78400.0000      1207.9148       0.0153         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                        Φ               ρ²             \n",
      "dataset                 0.0000          0.0000         \n",
      "label                   0.8723          0.8723         \n",
      "dataset x label         0.8577          0.8577         \n",
      "image:label             0.8956          0.8956         \n",
      "(image:label) x dataset 0.4970          0.8991         \n",
      "pixel:image:label       0.5599          0.5656         \n",
      "\n",
      "\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "-------------------- noise level: 0.1 --------------------\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                              dataset         label           dataset x label image:label     (image:label) x dataset pixel:image:label (pixel:image:label) x dataset mean            T               Variance       \n",
      "dataset                       78400.0000      7840.0000       7840.0000       1568.0000       1568.0000               2.0000            2.0000                        78400.0000      1204.6982       -0.0000        \n",
      "label                         39200.0000      78400.0000      39200.0000      8310.4000       7840.0000               10.6000           10.0000                       78400.0000      1286.5834       0.0010         \n",
      "dataset x label               78400.0000      78400.0000      78400.0000      15680.0000      15680.0000              20.0000           20.0000                       78400.0000      1298.3225       0.0002         \n",
      "image:label                   76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              100.0000          97.0000                       78400.0000      1352.5765       0.0008         \n",
      "(image:label) x dataset       78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              100.0000          100.0000                      78400.0000      1352.8706       -0.0001        \n",
      "pixel:image:label             76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              78400.0000        76048.0000                    78400.0000      8522.9169       0.0490         \n",
      "(pixel:image:label) x dataset 78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              78400.0000        78400.0000                    78400.0000      8626.2163       0.0439         \n",
      "mean                          39200.0000      7840.0000       3920.0000       831.0400        784.0000                1.0600            1.0000                        78400.0000      1204.4920       0.0153         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "Warning: Negative variance components found for Index(['(image:label) x dataset'], dtype='object'). Setting to 0.\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                        Φ               ρ²             \n",
      "dataset                 0.0000          0.0000         \n",
      "label                   0.8354          0.8354         \n",
      "dataset x label         0.8672          0.8672         \n",
      "image:label             0.8513          0.8513         \n",
      "(image:label) x dataset 0.4720          0.8941         \n",
      "pixel:image:label       0.5307          0.5364         \n",
      "\n",
      "\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "-------------------- noise level: 0.5 --------------------\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                              dataset         label           dataset x label image:label     (image:label) x dataset pixel:image:label (pixel:image:label) x dataset mean            T               Variance       \n",
      "dataset                       78400.0000      7840.0000       7840.0000       1568.0000       1568.0000               2.0000            2.0000                        78400.0000      1190.9156       -0.0000        \n",
      "label                         39200.0000      78400.0000      39200.0000      8310.4000       7840.0000               10.6000           10.0000                       78400.0000      1283.4008       0.0011         \n",
      "dataset x label               78400.0000      78400.0000      78400.0000      15680.0000      15680.0000              20.0000           20.0000                       78400.0000      1300.0819       0.0003         \n",
      "image:label                   76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              100.0000          97.0000                       78400.0000      1361.4039       0.0009         \n",
      "(image:label) x dataset       78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              100.0000          100.0000                      78400.0000      1362.0660       -0.0002        \n",
      "pixel:image:label             76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              78400.0000        76048.0000                    78400.0000      17607.3347      0.0505         \n",
      "(pixel:image:label) x dataset 78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              78400.0000        78400.0000                    78400.0000      17988.1928      0.1619         \n",
      "mean                          39200.0000      7840.0000       3920.0000       831.0400        784.0000                1.0600            1.0000                        78400.0000      1190.8495       0.0151         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "Warning: Negative variance components found for Index(['(image:label) x dataset'], dtype='object'). Setting to 0.\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                        Φ               ρ²             \n",
      "dataset                 0.0000          0.0000         \n",
      "label                   0.8012          0.8012         \n",
      "dataset x label         0.8567          0.8567         \n",
      "image:label             0.7803          0.7803         \n",
      "(image:label) x dataset 0.4279          0.8024         \n",
      "pixel:image:label       0.2432          0.2446         \n",
      "\n",
      "\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "-------------------- noise level: 0.9 --------------------\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                              dataset         label           dataset x label image:label     (image:label) x dataset pixel:image:label (pixel:image:label) x dataset mean            T               Variance       \n",
      "dataset                       78400.0000      7840.0000       7840.0000       1568.0000       1568.0000               2.0000            2.0000                        78400.0000      1177.2884       -0.0001        \n",
      "label                         39200.0000      78400.0000      39200.0000      8310.4000       7840.0000               10.6000           10.0000                       78400.0000      1282.6253       0.0011         \n",
      "dataset x label               78400.0000      78400.0000      78400.0000      15680.0000      15680.0000              20.0000           20.0000                       78400.0000      1306.6556       0.0004         \n",
      "image:label                   76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              100.0000          97.0000                       78400.0000      1392.0800       0.0008         \n",
      "(image:label) x dataset       78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              100.0000          100.0000                      78400.0000      1394.0073       -0.0001        \n",
      "pixel:image:label             76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              78400.0000        76048.0000                    78400.0000      38868.2235      0.0539         \n",
      "(pixel:image:label) x dataset 78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              78400.0000        78400.0000                    78400.0000      39898.5847      0.4378         \n",
      "mean                          39200.0000      7840.0000       3920.0000       831.0400        784.0000                1.0600            1.0000                        78400.0000      1177.2848       0.0149         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "Warning: Negative variance components found for Index(['dataset', '(image:label) x dataset'], dtype='object'). Setting to 0.\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                        Φ               ρ²             \n",
      "dataset                 0.0000          0.0000         \n",
      "label                   0.7597          0.7597         \n",
      "dataset x label         0.8401          0.8401         \n",
      "image:label             0.6524          0.6524         \n",
      "(image:label) x dataset 0.3758          0.6369         \n",
      "pixel:image:label       0.1129          0.1132         \n",
      "\n",
      "\n",
      "Processed 50 train images\n",
      "Processed 50 test images\n",
      "-------------------- noise level: 1.5 --------------------\n",
      "\n",
      "--------------------\n",
      "    ANOVA Table     \n",
      "--------------------\n",
      "                              dataset         label           dataset x label image:label     (image:label) x dataset pixel:image:label (pixel:image:label) x dataset mean            T               Variance       \n",
      "dataset                       78400.0000      7840.0000       7840.0000       1568.0000       1568.0000               2.0000            2.0000                        78400.0000      1157.1390       -0.0001        \n",
      "label                         39200.0000      78400.0000      39200.0000      8310.4000       7840.0000               10.6000           10.0000                       78400.0000      1285.9754       0.0013         \n",
      "dataset x label               78400.0000      78400.0000      78400.0000      15680.0000      15680.0000              20.0000           20.0000                       78400.0000      1325.5431       0.0006         \n",
      "image:label                   76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              100.0000          97.0000                       78400.0000      1479.0607       0.0006         \n",
      "(image:label) x dataset       78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              100.0000          100.0000                      78400.0000      1484.5675       0.0004         \n",
      "pixel:image:label             76048.0000      78400.0000      76048.0000      78400.0000      76048.0000              78400.0000        76048.0000                    78400.0000      93590.4398      0.0629         \n",
      "(pixel:image:label) x dataset 78400.0000      78400.0000      78400.0000      78400.0000      78400.0000              78400.0000        78400.0000                    78400.0000      96292.4519      1.1479         \n",
      "mean                          39200.0000      7840.0000       3920.0000       831.0400        784.0000                1.0600            1.0000                        78400.0000      1157.0834       0.0146         \n",
      "\n",
      "\n",
      "Using default variance tuple dictionary\n",
      "Using ANOVA Table Variance Dictionary for Generalizability Coefficients\n",
      "Warning: Negative variance components found for Index(['dataset'], dtype='object'). Setting to 0.\n",
      "\n",
      "--------------------\n",
      "   G Coefficients   \n",
      "--------------------\n",
      "                        Φ               ρ²             \n",
      "dataset                 0.0000          0.0000         \n",
      "label                   0.6995          0.6995         \n",
      "dataset x label         0.7887          0.7887         \n",
      "image:label             0.4312          0.4312         \n",
      "(image:label) x dataset 0.3825          0.5240         \n",
      "pixel:image:label       0.0537          0.0537         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for random_test_noise in [0, 0.1, 0.5, 0.9, 1.5]:    \n",
    "    train_test_data_df = prepare_data(num_images=50, num_images_test=50, test=True, display=False)\n",
    "\n",
    "    train_test_design_str = \"(pixel:image:label) x dataset\"\n",
    "    variance_tuple_dictionary = {\n",
    "        \"dataset\": (\"dataset\",),\n",
    "        \"label\": (\"label\",),\n",
    "        \"dataset x label\": (\"dataset\", \"label\"),\n",
    "        \"image:label\": (\"image\", \"label\"),\n",
    "        \"(image:label) x dataset\": (\"image\", \"label\", \"dataset\"),\n",
    "        \"pixel:image:label\": (\"pixel\", \"image\", \"label\"),\n",
    "        \"(pixel:image:label) x dataset\": (\"pixel\", \"image\", \"label\", \"dataset\"),\n",
    "        \"mean\": ()\n",
    "    }\n",
    "\n",
    "    # Add random noise to the 'test' portion of the train_test_data_df\n",
    "    # Find the indices of the test data\n",
    "    test_indices = train_test_data_df[train_test_data_df['dataset'] == 'train'].index\n",
    "    \n",
    "    # Add random noise to the 'value' column for these indices\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    # Adding noise to the test data\n",
    "    noise = np.random.normal(0, random_test_noise, len(test_indices)).astype(np.float32)\n",
    "    train_test_data_df.loc[test_indices, 'value'] += noise\n",
    "    print(f\"{'-'*20} noise level: {random_test_noise} {'-'*20}\")\n",
    "\n",
    "    gt_train_test = GeneralizIT(\n",
    "        data=train_test_data_df,\n",
    "        design_str=train_test_design_str,\n",
    "        response=\"value\",\n",
    "        variance_tuple_dictionary=variance_tuple_dictionary\n",
    "    )\n",
    "\n",
    "    gt_train_test.calculate_anova()\n",
    "    gt_train_test.anova_summary()\n",
    "    gt_train_test.calculate_g_coefficients()\n",
    "    gt_train_test.g_coefficients_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ff194",
   "metadata": {},
   "source": [
    "### Interpreting Label Corruption Results\n",
    "\n",
    "The experiment above reveals crucial insights about how adding noise to the training data affects the variance structure and G-coefficients:\n",
    "\n",
    "1. **Dataset Variance**: The variance (and hence G-coefficient) attributed to the dataset facet remains at 0, despite large increases in pixel noise!\n",
    "   - This may seem paradoxical at first, but remember that the noise added to the training data has mean 0 and is symmetric.\n",
    "   - Thus, on the dataset level, we've effectively added 0! The underlying data generating process remains unchanged.\n",
    "   - For your own experiments, try changing the mean of the noise to see how this affects the dataset variance. \n",
    "\n",
    "2. **Label Variance**: The variance attributed to the label facet steadily decreases as we increase the noise level. \n",
    "   - This indicates that the labels become less reliable as noise increases, which is expected since noise can obscure the true digit patterns.\n",
    "   - The G-coefficient for the label facet also decreases, indicating reduced reliability for digit classification.\n",
    "\n",
    "3. **Image:Label Variance**: The G-coefficient for the image:label facet steadily declines as noise increases, indicating that the images within each digit class become less distinguishable from one another.\n",
    "   - This suggests that the noise is overwhelming the true signal, making it harder to differentiate between images of the same digit.\n",
    "\n",
    "\n",
    "**ML Implications**: These findings highlight the importance of data augmentation techniques that can help models learn to be robust to noise. Training on noisy data does not disturb the underlying data generating process, but does add variance to the labels (without affecting the efficacy of labels, see `noise 0.1`) making it an effective tool for improving model robustness. G Theory can be used to estimate both optimal noise levels and number of augmented images needed to achieve a desired level of reliability (through D-studies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe74783",
   "metadata": {},
   "source": [
    "# Conclusion: Generalizability Theory as a Tool for ML Dataset Analysis\n",
    "\n",
    "Throughout this tutorial, we've explored how Generalizability Theory offers a powerful statistical framework for understanding the structure and reliability of machine learning datasets. Using MNIST as our case study, we've uncovered insights that traditional ML analytics often miss.\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### 1. Understanding Dataset Structure\n",
    "- **Variance Decomposition**: MNIST's variance is meaningfully distributed across digit classes, confirming its suitability for classification tasks\n",
    "- **Within-Class Patterns**: The image:label variance component quantifies the natural handwriting variations that models must learn to generalize across\n",
    "\n",
    "### 2. Detecting and Quantifying Data Drift\n",
    "- G-theory provides **precise metrics** for distribution shifts between training and test sets\n",
    "- The framework reveals **complex interaction patterns** between datasets and labels that simpler drift detection methods might overlook\n",
    "- G-coefficients offer **quantitative thresholds** for determining when drift becomes problematic\n",
    "\n",
    "### 3. Noise Analysis and Data Augmentation\n",
    "- We quantified exactly how different noise levels affect label reliability\n",
    "- Brightness scaling creates detectable drift requiring preprocessing adjustments\n",
    "- Adding Gaussian noise preserves underlying distributions while increasing the variance of images within a particular label—ideal for augmentation strategies\n",
    "\n",
    "### 4. Dataset Optimization through D-Studies\n",
    "- D-studies enable data scientists to **predict reliability improvements** from dataset modifications\n",
    "- This allows for **evidence-based decisions** about dataset size, composition, and augmentation strategies\n",
    "- Our comparison between predicted and actual results validates G-theory's predictive power\n",
    "\n",
    "## Limitations\n",
    "\n",
    "This tutorial focused on a single dataset (MNIST) and a specific set of toy experiments. Many machine learning models and pipelines are already designed with a generalizability focus in mind (though not explicitly using G-Theory). For example, data normalization and augmentation are common preprocessing steps while the actual model architecture (such as convolutions in CNNs) naturally provide spatial invariance properties. \n",
    "\n",
    "This tutorial also sampled only from at most the first 10 images of each digit class, whereas more robust data analysis would employ greater sampling along with bootstrapping techniques to provide confidence intervals around variance components and G-coefficients. Finally, all the experiments were conducted with balanced data, but one could imagine running G-Theory on unbalanced datasets (for example, one's real world pipeline may see many more `5's` than `0's`), etc.\n",
    "\n",
    "## Applications Beyond This Tutorial\n",
    "\n",
    "G-theory's applications extend far beyond basic dataset analysis:\n",
    "\n",
    "- **Model Evaluation**: Assess whether performance differences across model architectures represent reliable, generalizable improvements\n",
    "- **Benchmark Design**: Create more reliable ML benchmarks by understanding variance components\n",
    "- **Hyperparameter Analysis**: Determine which hyperparameters consistently impact performance across different datasets\n",
    "- **Data Quality Monitoring**: Implement ongoing monitoring for production ML systems to detect subtle data quality issues\n",
    "\n",
    "## Final Thoughts\n",
    "\n",
    "As machine learning systems increasingly impact critical domains, understanding dataset reliability becomes as important as model architecture. Generalizability Theory provides the statistical rigor needed to:\n",
    "\n",
    "1. Build more reliable training datasets\n",
    "2. Detect data quality issues before they affect model performance\n",
    "3. Make informed decisions about data collection and augmentation\n",
    "4. Establish confidence intervals around model performance metrics\n",
    "\n",
    "By integrating G-theory into ML workflows, practitioners can move beyond treating datasets as fixed inputs and instead approach them as statistical measurement instruments with quantifiable reliability properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
